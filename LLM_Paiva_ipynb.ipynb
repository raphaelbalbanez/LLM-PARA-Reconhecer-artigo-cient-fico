{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pymupdf pdfplumber pillow pytesseract opencv-python numpy unidecode\n",
        "# Tesseract binário (Linux/Colab)\n",
        "!apt -q install -y tesseract-ocr >/dev/null\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkJaQM8k8kuT",
        "outputId": "c830e2cf-e908-4095-cdee-1b532ca9a9ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m123.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, json, io, math, tempfile\n",
        "from typing import List, Tuple, Dict, Any\n",
        "from collections import Counter\n",
        "\n",
        "import fitz                     # PyMuPDF\n",
        "import pdfplumber\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from unidecode import unidecode\n",
        "\n",
        "WORD_RE = re.compile(r\"[A-Za-zÀ-ÿ]+\", re.UNICODE)\n",
        "\n",
        "STOPWORDS_EN = set('''a about above after again against all am an and any are aren't as at be because been before being below between both\n",
        "but by can't cannot could couldn't did didn't do does doesn't doing don't down during each few for from further had hadn't has hasn't have\n",
        "haven't having he he'd he'll he's her here here's hers herself him himself his how how's i i'd i'll i'm i've if in into is isn't it it's its\n",
        "itself let's me more most mustn't my myself no nor not of off on once only or other ought our ours ourselves out over own same shan't she she'd\n",
        "she'll she's should shouldn't so some such than that that's the their theirs them themselves then there there's these they they'd they'll they're\n",
        "they've this those through to too under until up very was wasn't we we'd we'll we're we've were weren't what what's when when's where where's which\n",
        "while who who's whom why why's with won't would wouldn't you you'd you'll you're you've your yours yourself yourselves'''.split())\n",
        "\n",
        "STOPWORDS_PT = set('''a ao aos à às acima ainda algo alguma algumas algum alguns ambas ambos ante após aquele aquela aquelas aqueles aquilo as assim\n",
        "até abaixo bem boa bom bons boas cada com como contra cujo cuja cujas cujos da das de dela delas dele deles demais depois desde desta deste disto do dos\n",
        "e ela elas ele eles em enquanto entre era eram será foram foi grande grandes há isso isto já la lá lhes lhe mais mas me mesma mesmas mesmo mesmos meu\n",
        "meus minha minhas muito muita muitas muitos na nas não nem nos nós o os ou onde outra outras outro outros para pela pelas pelo pelos pequena pequenas pequeno\n",
        "pequenos perante pode podem por porque porém pouca poucas pouco poucos portanto próprio própria próprias próprios qual quais quando que quem se sem será seu seus\n",
        "sua suas sob sobre sua suas também tão tal tais te tem têm tendo tenho temos tive tivemos tiveram tua tuas teu teus tua teu um uma umas uns vendo vos vocês'''.split())\n",
        "\n",
        "def is_pdf(path: str) -> bool:\n",
        "    return path.lower().endswith(\".pdf\")\n",
        "\n",
        "def tokenize(text: str) -> List[str]:\n",
        "    tokens = [t.lower() for t in WORD_RE.findall(text)]\n",
        "    # normalização leve ajuda o contador\n",
        "    tokens = [unidecode(t) for t in tokens]\n",
        "    return [t for t in tokens if t not in STOPWORDS_EN and t not in STOPWORDS_PT and len(t) > 1]\n",
        "\n",
        "def most_frequent_words(text: str, top_k: int = 30) -> List[Tuple[str,int]]:\n",
        "    return Counter(tokenize(text)).most_common(top_k)\n",
        "\n",
        "def paragraphs_from_text(text: str) -> List[str]:\n",
        "    # separa por linhas em branco; fallback por duplo espaço entre sentenças\n",
        "    paras = [p.strip() for p in re.split(r\"\\n\\s*\\n+\", text) if p.strip()]\n",
        "    if len(paras) <= 1:\n",
        "        paras = [p.strip() for p in re.split(r\"(?<=[.!?])\\s{2,}\", text) if p.strip()]\n",
        "    return paras\n",
        "\n",
        "def looks_like_scientific_article(text: str) -> bool:\n",
        "    \"\"\"Heurística: presença de múltiplas pistas comuns em artigos científicos (PT/EN).\"\"\"\n",
        "    if not text or len(text) < 500:\n",
        "        return False\n",
        "    cues = [\n",
        "        r\"\\babstract\\b\", r\"\\bresumo\\b\", r\"\\bintroduc[aã]o\\b\", r\"\\bintroduction\\b\",\n",
        "        r\"\\bmetodolog[ií]a\\b\", r\"\\bmethods?\\b\", r\"\\bmaterials\\b\", r\"\\bresults?\\b\", r\"\\bresultados\\b\",\n",
        "        r\"\\bdiscuss[aã]o\\b\", r\"\\bdiscussion\\b\", r\"\\bconclus[aã]o\\b\", r\"\\bconclusion\\b\",\n",
        "        r\"\\brefer[eê]ncias\\b\", r\"\\breferences\\b\", r\"\\bkeywords?\\b\", r\"\\bpalavras[-\\s]?chave\\b\",\n",
        "        r\"\\bdoi:\\s*10\\.\\d{4,9}/\\S+\", r\"\\bissn\\b\", r\"\\buniversidade\\b\", r\"\\buniversity\\b\"\n",
        "    ]\n",
        "    hits = sum(1 for pat in cues if re.search(pat, text, flags=re.IGNORECASE))\n",
        "    return hits >= 3\n"
      ],
      "metadata": {
        "id": "UQk8SGIe8u6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_pdf_text_and_paragraphs(path: str) -> Tuple[str, List[str]]:\n",
        "    \"\"\"\n",
        "    1) Tenta segmentação por blocos com PyMuPDF (layout-aware).\n",
        "    2) Se vier muito pouco texto, tenta OCR por página (renderiza imagem e passa Tesseract).\n",
        "    \"\"\"\n",
        "    text_blocks = []\n",
        "    have_text = False\n",
        "\n",
        "    with fitz.open(path) as doc:\n",
        "        for page in doc:\n",
        "            try:\n",
        "                blocks = page.get_text(\"blocks\")  # [(x0,y0,x1,y1,text,block_no,...)]\n",
        "                blocks = sorted(blocks, key=lambda b: (round(b[1],1), round(b[0],1)))\n",
        "                page_texts = [(b[4] or \"\").strip() for b in blocks if (b[4] or \"\").strip()]\n",
        "                if page_texts:\n",
        "                    have_text = True\n",
        "                    text_blocks.extend(page_texts)\n",
        "                else:\n",
        "                    text_blocks.append(\"\")  # placeholder\n",
        "            except Exception:\n",
        "                text_blocks.append(\"\")  # placeholder\n",
        "\n",
        "        joined_text = \"\\n\\n\".join([t for t in text_blocks if t])\n",
        "        # Se o PDF não tinha texto (provável scan), faz OCR por página\n",
        "        if not have_text or len(joined_text) < 300:\n",
        "            ocr_texts = []\n",
        "            for i, page in enumerate(doc):\n",
        "                pix = page.get_pixmap(dpi=200)\n",
        "                img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
        "                ocr_texts.append(pytesseract.image_to_string(img, lang=\"por+eng\").strip())\n",
        "            joined_text = \"\\n\\n\".join([t for t in ocr_texts if t])\n",
        "\n",
        "    paragraphs = paragraphs_from_text(joined_text)\n",
        "    return joined_text, paragraphs\n"
      ],
      "metadata": {
        "id": "25XKV2oW8z0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_image_text_and_paragraphs(path: str) -> Tuple[str, List[str]]:\n",
        "    img = cv2.imread(path)\n",
        "    if img is None:\n",
        "        # fallback: tenta abrir com PIL (formatos diferenciados)\n",
        "        pil = Image.open(path).convert(\"RGB\")\n",
        "        text = pytesseract.image_to_string(pil, lang=\"por+eng\")\n",
        "        return text, paragraphs_from_text(text)\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "                                cv2.THRESH_BINARY_INV, 31, 15)\n",
        "\n",
        "    # kernel que aglutina linhas em blocos tipo parágrafos\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 5))\n",
        "    closed = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
        "\n",
        "    contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    h, w = closed.shape\n",
        "    boxes = []\n",
        "    for cnt in contours:\n",
        "        x, y, bw, bh = cv2.boundingRect(cnt)\n",
        "        area = bw * bh\n",
        "        if area < 500 or bw < 40 or bh < 20:     # ruído\n",
        "            continue\n",
        "        if bw > 0.98*w and bh > 0.98*h:          # quase página inteira\n",
        "            continue\n",
        "        boxes.append((x, y, bw, bh))\n",
        "\n",
        "    boxes.sort(key=lambda b: (b[1], b[0]))  # top-to-bottom, left-to-right\n",
        "\n",
        "    pil_img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    paragraphs, parts = [], []\n",
        "    for (x, y, bw, bh) in boxes:\n",
        "        crop = pil_img.crop((x, y, x+bw, y+bh))\n",
        "        txt = pytesseract.image_to_string(crop, lang=\"por+eng\").strip()\n",
        "        if txt:\n",
        "            paragraphs.append(txt)\n",
        "            parts.append(txt)\n",
        "\n",
        "    full_text = \"\\n\\n\".join(parts)\n",
        "    if not full_text:\n",
        "        # fallback: OCR da imagem toda\n",
        "        full_text = pytesseract.image_to_string(pil_img, lang=\"por+eng\")\n",
        "        paragraphs = paragraphs_from_text(full_text)\n",
        "\n",
        "    return full_text, paragraphs\n"
      ],
      "metadata": {
        "id": "qz6W3fJa86Om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_file(path: str) -> Dict[str, Any]:\n",
        "    if is_pdf(path):\n",
        "        text, paras = extract_pdf_text_and_paragraphs(path)\n",
        "    else:\n",
        "        text, paras = extract_image_text_and_paragraphs(path)\n",
        "\n",
        "    if text and not paras:\n",
        "        paras = paragraphs_from_text(text)\n",
        "\n",
        "    word_count = len(WORD_RE.findall(text))\n",
        "    top_words = most_frequent_words(text, top_k=50)\n",
        "    is_article = looks_like_scientific_article(text)\n",
        "    compliant = bool(word_count > 2000 and len(paras) > 4)\n",
        "\n",
        "    report = {\n",
        "        \"input_path\": os.path.abspath(path),\n",
        "        \"is_pdf\": is_pdf(path),\n",
        "        \"is_scientific_article\": is_article,\n",
        "        \"paragraph_count\": len(paras),\n",
        "        \"word_count\": word_count,\n",
        "        \"top_words\": top_words,                   # lista de [palavra, contagem]\n",
        "        \"paragraphs\": paras,                      # parágrafos extraídos\n",
        "        \"compliant_to_rule\": compliant,\n",
        "        \"rule\": \">2000 palavras e >4 parágrafos\"\n",
        "    }\n",
        "    return report\n",
        "\n",
        "def save_report(report: Dict[str, Any]) -> str:\n",
        "    base, ext = os.path.splitext(os.path.basename(report[\"input_path\"]))\n",
        "    out = f\"/content/{base}_report.json\"\n",
        "    with open(out, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(report, f, ensure_ascii=False, indent=2)\n",
        "    return out\n",
        "\n",
        "def print_machine_summary(report: Dict[str, Any]):\n",
        "    \"\"\"Resumo objetivo (sem LLM): serve para rápida inspeção.\"\"\"\n",
        "    print(\"# Resumo técnico (sem LLM)\")\n",
        "    print(f\"- Arquivo: {report['input_path']}\")\n",
        "    print(f\"- PDF? {report['is_pdf']}\")\n",
        "    print(f\"- Parece artigo científico? {report['is_scientific_article']}\")\n",
        "    print(f\"- Parágrafos: {report['paragraph_count']}\")\n",
        "    print(f\"- Palavras: {report['word_count']}\")\n",
        "    print(f\"- Regra (>2000 palavras e >4 parágrafos): {report['compliant_to_rule']}\")\n",
        "    print(\"\\nTop palavras (base PT/EN stopwords removidas):\")\n",
        "    for w, c in report[\"top_words\"][:20]:\n",
        "        print(f\"  {w:20s} {c}\")\n"
      ],
      "metadata": {
        "id": "24u53vLI88MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Envie 1 ou mais arquivos (PDF/PNG/JPG):\")\n",
        "uploaded = files.upload()  # abra o seletor, escolha seus arquivos\n",
        "\n",
        "reports = []\n",
        "for name in uploaded.keys():\n",
        "    path = f\"/content/{name}\"\n",
        "    print(f\"\\n=== Processando: {path} ===\")\n",
        "    rep = analyze_file(path)\n",
        "    out = save_report(rep)\n",
        "    print_machine_summary(rep)\n",
        "    print(f\"\\n➡ Relatório salvo em: {out}\")\n",
        "    reports.append(rep)\n",
        "\n",
        "# Também salva\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "ljO-ntdX8_Tl",
        "outputId": "85efccb4-9967-4364-e367-4f58586865a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Envie 1 ou mais arquivos (PDF/PNG/JPG):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dac4d9fd-ecec-448c-902c-472ddc1d30cd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dac4d9fd-ecec-448c-902c-472ddc1d30cd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving images.jpg to images.jpg\n",
            "\n",
            "=== Processando: /content/images.jpg ===\n",
            "# Resumo técnico (sem LLM)\n",
            "- Arquivo: /content/images.jpg\n",
            "- PDF? False\n",
            "- Parece artigo científico? False\n",
            "- Parágrafos: 1\n",
            "- Palavras: 5\n",
            "- Regra (>2000 palavras e >4 parágrafos): False\n",
            "\n",
            "Top palavras (base PT/EN stopwords removidas):\n",
            "  oe                   1\n",
            "  rh                   1\n",
            "  ee                   1\n",
            "  ro                   1\n",
            "\n",
            "➡ Relatório salvo em: /content/images_report.json\n"
          ]
        }
      ]
    }
  ]
}